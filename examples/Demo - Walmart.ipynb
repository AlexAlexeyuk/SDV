{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo \"walmart\"\n",
    "\n",
    "We have a store series, each of those have a size and a category and additional information in a given date: average temperature in the region, cost of fuel in the region, promotional data, the customer price index, the unemployment rate and whether the date is a special holiday.\n",
    "\n",
    "From those stores we obtained a training of historical data \n",
    "between 2010-02-05 and 2012-11-01. This historical data includes the sales of each department on a specific date.\n",
    "In this notebook, we will show you step-by-step how to download the \"Walmart\" dataset, explain the structure and sample the data.\n",
    "\n",
    "In this demonstration we will show how SDV can be used to generate synthetic data. And lately, this data can be used to train machine learning models.\n",
    "\n",
    "*The dataset used in this example can be found in [Kaggle](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/data), but we will show how to download it from SDV.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\"><b>stores</b><p>\n",
    "\n",
    "| Field | Type        | Subtype | Additional Properties |\n",
    "|-------|-------------|---------|-----------------------|\n",
    "| Store | id          | integer | Primary key           |\n",
    "| Size  | numerical   | integer |                       |\n",
    "| Type  | categorical |         |                       |\n",
    "\n",
    "Contains information about the 45 stores, indicating the type and size of store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\"><b>features</b><p>\n",
    "\n",
    "| Fields       | Type      | Subtype | Additional Properties       |\n",
    "|--------------|-----------|---------|-----------------------------|\n",
    "| Store        | id        | integer | foreign key (stores.Store)  |\n",
    "| Date         | datetime  |         | format: \"%Y-%m-%d\"          |\n",
    "| IsHoliday    | boolean   |         |                             |\n",
    "| Fuel_Price   | numerical | float   |                             |\n",
    "| Unemployment | numerical | float   |                             |\n",
    "| Temperature  | numerical | float   |                             |\n",
    "| CPI          | numerical | float   |                             |\n",
    "| MarkDown1    | numerical | float   |                             |\n",
    "| MarkDown2    | numerical | float   |                             |\n",
    "| MarkDown3    | numerical | float   |                             |\n",
    "| MarkDown4    | numerical | float   |                             |\n",
    "| MarkDown5    | numerical | float   |                             |\n",
    "\n",
    "Contains historical training data, which covers to 2010-02-05 to 2012-11-01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\"><b>depts</b><p>\n",
    "\n",
    "| Fields       | Type      | Subtype | Additional Properties        |\n",
    "|--------------|-----------|---------|------------------------------|\n",
    "| Store        | id        | integer | foreign key (stores.Stores)  |\n",
    "| Date         | datetime  |         | format: \"%Y-%m-%d\"           |\n",
    "| Weekly_Sales | numerical | float   |                              |\n",
    "| Dept         | numerical | integer |                              |\n",
    "| IsHoliday    | boolean   |         |                              |\n",
    "\n",
    "Contains additional data related to the store, department, and regional activity for the given dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data\n",
    "\n",
    "Let's start downloading the data set. In this case, we will download the data set *walmart*. We will use the SDV function `load_demo`, we can specify the name of the dataset we want to use and if we want its Metadata object or not. To know more about the demo data [see the documentation](https://sdv-dev.github.io/SDV/api/sdv.demo.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-02 18:50:09,230 - INFO - metadata - Loading table stores\n",
      "2020-07-02 18:50:09,237 - INFO - metadata - Loading table features\n",
      "2020-07-02 18:50:09,255 - INFO - metadata - Loading table depts\n"
     ]
    }
   ],
   "source": [
    "from sdv import load_demo\n",
    "\n",
    "metadata, tables = load_demo(dataset_name='walmart', metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is downloaded from an [Amazon S3 bucket](http://sdv-datasets.s3.amazonaws.com/index.html) that contains all available data sets of the `load_demo` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the metadata structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Metadata Pages: 1 -->\n",
       "<svg width=\"470pt\" height=\"424pt\"\n",
       " viewBox=\"0.00 0.00 469.50 424.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 420)\">\n",
       "<title>Metadata</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-420 465.5,-420 465.5,4 -4,4\"/>\n",
       "<!-- stores -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>stores</title>\n",
       "<path fill=\"#ffec8b\" stroke=\"#000000\" d=\"M146,-301.5C146,-301.5 277,-301.5 277,-301.5 283,-301.5 289,-307.5 289,-313.5 289,-313.5 289,-403.5 289,-403.5 289,-409.5 283,-415.5 277,-415.5 277,-415.5 146,-415.5 146,-415.5 140,-415.5 134,-409.5 134,-403.5 134,-403.5 134,-313.5 134,-313.5 134,-307.5 140,-301.5 146,-301.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"211.5\" y=\"-400.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stores</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"134,-392.5 289,-392.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"142\" y=\"-377.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Type : categorical</text>\n",
       "<text text-anchor=\"start\" x=\"142\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Size : numerical &#45; integer</text>\n",
       "<text text-anchor=\"start\" x=\"142\" y=\"-347.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Store : id &#45; integer</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"134,-339.5 289,-339.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"142\" y=\"-324.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Primary key: Store</text>\n",
       "<text text-anchor=\"start\" x=\"142\" y=\"-309.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Data path: stores.csv</text>\n",
       "</g>\n",
       "<!-- features -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>features</title>\n",
       "<path fill=\"#ffec8b\" stroke=\"#000000\" d=\"M12,-.5C12,-.5 193,-.5 193,-.5 199,-.5 205,-6.5 205,-12.5 205,-12.5 205,-237.5 205,-237.5 205,-243.5 199,-249.5 193,-249.5 193,-249.5 12,-249.5 12,-249.5 6,-249.5 0,-243.5 0,-237.5 0,-237.5 0,-12.5 0,-12.5 0,-6.5 6,-.5 12,-.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"102.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">features</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"0,-226.5 205,-226.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-211.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Date : datetime</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-196.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MarkDown1 : numerical &#45; float</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-181.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Store : id &#45; integer</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-166.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">IsHoliday : boolean</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-151.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MarkDown4 : numerical &#45; float</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-136.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MarkDown3 : numerical &#45; float</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-121.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Fuel_Price : numerical &#45; float</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-106.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Unemployment : numerical &#45; float</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Temperature : numerical &#45; float</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MarkDown5 : numerical &#45; float</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-61.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MarkDown2 : numerical &#45; float</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">CPI : numerical &#45; float</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"0,-38.5 205,-38.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-23.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Foreign key (stores): Store</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Data path: features.csv</text>\n",
       "</g>\n",
       "<!-- stores&#45;&gt;features -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>stores&#45;&gt;features</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.7572,-301.1781C136.1229,-295.4114 131.9421,-289.3324 128.5,-283 124.4445,-275.5391 120.9867,-267.6091 118.0416,-259.4282\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"117.9697,-259.2116 119.085,-248.3026 116.3922,-254.467 114.8148,-249.7223 114.8148,-249.7223 114.8148,-249.7223 116.3922,-254.467 110.5446,-251.142 117.9697,-259.2116 117.9697,-259.2116\"/>\n",
       "<text text-anchor=\"middle\" x=\"214\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> &#160;&#160;features.Store &#45;&gt; stores.Store</text>\n",
       "</g>\n",
       "<!-- depts -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>depts</title>\n",
       "<path fill=\"#ffec8b\" stroke=\"#000000\" d=\"M235,-53C235,-53 408,-53 408,-53 414,-53 420,-59 420,-65 420,-65 420,-185 420,-185 420,-191 414,-197 408,-197 408,-197 235,-197 235,-197 229,-197 223,-191 223,-185 223,-185 223,-65 223,-65 223,-59 229,-53 235,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"321.5\" y=\"-181.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">depts</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"223,-174 420,-174 \"/>\n",
       "<text text-anchor=\"start\" x=\"231\" y=\"-158.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Date : datetime</text>\n",
       "<text text-anchor=\"start\" x=\"231\" y=\"-143.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Weekly_Sales : numerical &#45; float</text>\n",
       "<text text-anchor=\"start\" x=\"231\" y=\"-128.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Store : id &#45; integer</text>\n",
       "<text text-anchor=\"start\" x=\"231\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Dept : numerical &#45; integer</text>\n",
       "<text text-anchor=\"start\" x=\"231\" y=\"-98.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">IsHoliday : boolean</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"223,-91 420,-91 \"/>\n",
       "<text text-anchor=\"start\" x=\"231\" y=\"-75.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Foreign key (stores): Store</text>\n",
       "<text text-anchor=\"start\" x=\"231\" y=\"-60.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Data path: train.csv</text>\n",
       "</g>\n",
       "<!-- stores&#45;&gt;depts -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>stores&#45;&gt;depts</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M287.0707,-301.1494C291.788,-295.4236 296.0255,-289.3596 299.5,-283 311.9843,-260.1491 318.266,-232.7713 321.2171,-207.274\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.2259,-207.1848 326.7005,-197.6832 321.7244,-202.2097 322.223,-197.2346 322.223,-197.2346 322.223,-197.2346 321.7244,-202.2097 317.7454,-196.7859 321.2259,-207.1848 321.2259,-207.1848\"/>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> &#160;&#160;depts.Store &#45;&gt; stores.Store</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc286fd97f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also validate that the metadata is correctly defined for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.validate(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create an instance of SDV and train the instance\n",
    "\n",
    "Once we download it, we have to create an SDV instance. With that instance, we have to analyze the loaded tables to generate a statistical model from the data. In this case, the process of adjusting the model is quickly because the dataset is small. However, with larger datasets it can be a slow process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-02 18:50:09,639 - INFO - modeler - Modeling stores\n",
      "2020-07-02 18:50:09,640 - INFO - metadata - Loading transformer CategoricalTransformer for field Type\n",
      "2020-07-02 18:50:09,640 - INFO - metadata - Loading transformer NumericalTransformer for field Size\n",
      "2020-07-02 18:50:09,653 - INFO - modeler - Modeling features\n",
      "2020-07-02 18:50:09,653 - INFO - metadata - Loading transformer DatetimeTransformer for field Date\n",
      "2020-07-02 18:50:09,654 - INFO - metadata - Loading transformer NumericalTransformer for field MarkDown1\n",
      "2020-07-02 18:50:09,654 - INFO - metadata - Loading transformer BooleanTransformer for field IsHoliday\n",
      "2020-07-02 18:50:09,654 - INFO - metadata - Loading transformer NumericalTransformer for field MarkDown4\n",
      "2020-07-02 18:50:09,655 - INFO - metadata - Loading transformer NumericalTransformer for field MarkDown3\n",
      "2020-07-02 18:50:09,656 - INFO - metadata - Loading transformer NumericalTransformer for field Fuel_Price\n",
      "2020-07-02 18:50:09,656 - INFO - metadata - Loading transformer NumericalTransformer for field Unemployment\n",
      "2020-07-02 18:50:09,657 - INFO - metadata - Loading transformer NumericalTransformer for field Temperature\n",
      "2020-07-02 18:50:09,657 - INFO - metadata - Loading transformer NumericalTransformer for field MarkDown5\n",
      "2020-07-02 18:50:09,657 - INFO - metadata - Loading transformer NumericalTransformer for field MarkDown2\n",
      "2020-07-02 18:50:09,659 - INFO - metadata - Loading transformer NumericalTransformer for field CPI\n",
      "2020-07-02 18:50:09,709 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:09,760 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:09,791 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:09,817 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:09,845 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:09,871 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:09,901 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:09,929 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:09,958 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:09,985 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,016 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,045 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,076 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,131 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,158 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,184 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,211 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,239 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,268 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,297 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,325 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,352 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,378 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,410 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,440 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,467 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,494 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,519 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,547 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,572 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,602 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,628 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,656 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,686 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,713 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,740 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,768 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,799 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,827 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,858 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,886 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,912 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,939 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,967 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:10,996 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,028 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,058 - INFO - modeler - Modeling depts\n",
      "2020-07-02 18:50:11,058 - INFO - metadata - Loading transformer DatetimeTransformer for field Date\n",
      "2020-07-02 18:50:11,059 - INFO - metadata - Loading transformer NumericalTransformer for field Weekly_Sales\n",
      "2020-07-02 18:50:11,059 - INFO - metadata - Loading transformer NumericalTransformer for field Dept\n",
      "2020-07-02 18:50:11,059 - INFO - metadata - Loading transformer BooleanTransformer for field IsHoliday\n",
      "2020-07-02 18:50:11,169 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,445 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,461 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,474 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,489 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,505 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,521 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,536 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,552 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,568 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,583 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,603 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-02 18:50:11,618 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,634 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,652 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,667 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,683 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,698 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,713 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,728 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,741 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,754 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,769 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,782 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,800 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,814 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,829 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,844 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,859 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,874 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,887 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,900 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,914 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,928 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,940 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,955 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,968 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,979 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:11,991 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:12,003 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:12,017 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:12,032 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:12,045 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:12,058 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:12,069 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:12,084 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "2020-07-02 18:50:12,177 - INFO - gaussian - Fitting GaussianMultivariate(distribution=\"GaussianUnivariate\")\n",
      "/home/xals/.virtualenvs/SDV/lib/python3.6/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n",
      "2020-07-02 18:50:12,380 - INFO - modeler - Modeling Complete\n"
     ]
    }
   ],
   "source": [
    "from sdv import SDV\n",
    "\n",
    "sdv = SDV()\n",
    "sdv.fit(metadata, tables=tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We may not want to train the model every time we want to generate new synthetic data. We can [save](https://sdv-dev.github.io/SDV/api/sdv.sdv.html#sdv.sdv.SDV.save) the SDV instance to [load](https://sdv-dev.github.io/SDV/api/sdv.sdv.html#sdv.sdv.SDV.save) it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate synthetic data\n",
    "\n",
    "Once the instance is trained, we are ready to generate the synthetic data.\n",
    "\n",
    "The easiest way to generate synthetic data for the entire dataset is to call the `sample_all` method. By default, this method generates only 5 rows, but we can specify the row number that will be generated with the `num_rows` argument. To learn more about the available arguments, see [sample_all](https://sdv-dev.github.io/SDV/api/sdv.sampler.html#sdv.sampler.Sampler.sample_all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stores': 45, 'features': 8190, 'depts': 421570}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdv.modeler.table_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples = sdv.sample_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a dictionary with a `pandas.DataFrame` for each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>85496</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>178862</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>69654</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>211981</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>131188</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type    Size  Store\n",
       "0    B   85496      3\n",
       "1    A  178862      4\n",
       "2    B   69654      5\n",
       "3    A  211981      6\n",
       "4    A  131188      7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['stores'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>Store</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>CPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-04-23 03:09:52.638271488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9803.940199</td>\n",
       "      <td>3.561375</td>\n",
       "      <td>8.838728</td>\n",
       "      <td>67.162475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2703.17729</td>\n",
       "      <td>186.471991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-19 08:45:12.429521664</td>\n",
       "      <td>483.892955</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>7504.524416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.495118</td>\n",
       "      <td>7.360667</td>\n",
       "      <td>42.785730</td>\n",
       "      <td>2772.597105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.048268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-30 22:13:59.841415680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.361946</td>\n",
       "      <td>7.524812</td>\n",
       "      <td>34.945770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.100673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-08 08:16:00.977235968</td>\n",
       "      <td>4661.175670</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>3392.028528</td>\n",
       "      <td>-5837.649003</td>\n",
       "      <td>2.994273</td>\n",
       "      <td>7.993152</td>\n",
       "      <td>66.818180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197.921916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-29 23:18:43.912751616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.116659</td>\n",
       "      <td>4.945393</td>\n",
       "      <td>48.979036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2957.77612</td>\n",
       "      <td>192.677797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date    MarkDown1  Store  IsHoliday    MarkDown4  \\\n",
       "0 2012-04-23 03:09:52.638271488          NaN      3      False          NaN   \n",
       "1 2011-04-19 08:45:12.429521664   483.892955      3      False  7504.524416   \n",
       "2 2011-01-30 22:13:59.841415680          NaN      3      False          NaN   \n",
       "3 2011-10-08 08:16:00.977235968  4661.175670      3      False  3392.028528   \n",
       "4 2011-09-29 23:18:43.912751616          NaN      3      False          NaN   \n",
       "\n",
       "     MarkDown3  Fuel_Price  Unemployment  Temperature    MarkDown5  \\\n",
       "0 -9803.940199    3.561375      8.838728    67.162475          NaN   \n",
       "1          NaN    3.495118      7.360667    42.785730  2772.597105   \n",
       "2          NaN    3.361946      7.524812    34.945770          NaN   \n",
       "3 -5837.649003    2.994273      7.993152    66.818180          NaN   \n",
       "4          NaN    3.116659      4.945393    48.979036          NaN   \n",
       "\n",
       "    MarkDown2         CPI  \n",
       "0  2703.17729  186.471991  \n",
       "1         NaN  192.048268  \n",
       "2         NaN  192.100673  \n",
       "3         NaN  197.921916  \n",
       "4  2957.77612  192.677797  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['features'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-22 15:24:18.057608704</td>\n",
       "      <td>11196.989134</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-06 19:21:02.431538688</td>\n",
       "      <td>-14038.529503</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-06-04 16:23:09.227934976</td>\n",
       "      <td>-6519.738485</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-08-09 17:18:54.910250752</td>\n",
       "      <td>23194.918038</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-09-01 23:10:54.986872576</td>\n",
       "      <td>16761.426407</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date  Weekly_Sales  Store  Dept  IsHoliday\n",
       "0 2011-04-22 15:24:18.057608704  11196.989134      3    38      False\n",
       "1 2010-02-06 19:21:02.431538688 -14038.529503      3    29      False\n",
       "2 2012-06-04 16:23:09.227934976  -6519.738485      3    46      False\n",
       "3 2011-08-09 17:18:54.910250752  23194.918038      3    45      False\n",
       "4 2010-09-01 23:10:54.986872576  16761.426407      3    29      False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['depts'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may not want to generate data for all tables in the dataset, rather for just one table. This is possible with SDV using the `sample` method. To use it we only need to specify the name of the table we want to synthesize and the row numbers to generate. In this case, the \"walmart\" data set has 3 tables: stores, features and depts.\n",
    "\n",
    "In the following example, we will generate 1000 rows of the \"features\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features':                              Date     MarkDown1  Store  IsHoliday  \\\n",
       " 0   2012-03-09 19:29:04.121987584   4547.265066     48      False   \n",
       " 1   2012-01-12 12:05:27.772331264           NaN     51      False   \n",
       " 2   2012-10-09 23:52:58.454752256  13291.983302     51      False   \n",
       " 3   2011-07-26 23:58:33.986580992           NaN     49      False   \n",
       " 4   2012-01-17 02:27:51.821400832   6865.756770     50      False   \n",
       " 5   2009-12-27 02:32:16.625306880           NaN     51      False   \n",
       " 6   2011-07-12 23:01:03.955540224           NaN     48      False   \n",
       " 7   2011-09-25 10:16:19.542280704   7114.339579     48      False   \n",
       " 8   2011-05-06 02:00:24.919497728           NaN     48      False   \n",
       " 9   2013-10-23 10:17:59.945650432   2267.991754     50      False   \n",
       " 10  2011-05-18 08:31:22.419635968           NaN     48      False   \n",
       " 11  2010-07-27 18:16:54.600127744           NaN     49      False   \n",
       " 12  2010-11-04 00:37:47.996870656           NaN     51      False   \n",
       " 13  2012-03-23 15:04:51.172607488  10192.668685     48      False   \n",
       " 14  2007-11-14 22:28:51.711726848           NaN     48      False   \n",
       " 15  2013-02-07 20:55:46.684175872   9146.998153     49      False   \n",
       " 16  2011-07-18 00:03:42.998976512           NaN     50      False   \n",
       " 17  2010-10-02 21:34:09.917561088           NaN     49      False   \n",
       " 18  2010-03-12 18:25:31.509475328           NaN     51      False   \n",
       " 19  2013-06-24 02:50:15.027540736   2943.979267     50      False   \n",
       " 20  2010-09-24 15:42:39.457930752           NaN     48      False   \n",
       " 21  2012-03-27 19:00:12.877346816   7750.605869     51      False   \n",
       " 22  2010-05-26 23:28:27.091251968           NaN     48      False   \n",
       " 23  2011-05-01 23:07:37.680983296           NaN     52      False   \n",
       " 24  2012-10-07 16:56:39.076689152  11838.898938     51      False   \n",
       " 25  2011-02-19 21:38:01.903840000           NaN     52      False   \n",
       " 26  2012-01-18 06:02:24.764590592   7428.686729     52      False   \n",
       " 27  2012-09-28 01:36:19.603453184   4962.148181     52      False   \n",
       " 28  2011-07-28 19:21:49.952510208  12773.901269     48      False   \n",
       " 29  2011-09-04 16:53:45.561477888           NaN     50      False   \n",
       " ..                            ...           ...    ...        ...   \n",
       " 970 2011-06-14 18:48:47.646437632   7563.489728     48      False   \n",
       " 971 2011-05-11 09:27:03.321238016   3763.579757     50      False   \n",
       " 972 2012-10-27 08:44:16.987041024  -2107.559543     49      False   \n",
       " 973 2011-03-26 17:36:28.323915264           NaN     48      False   \n",
       " 974 2012-03-30 09:18:45.289797888           NaN     52      False   \n",
       " 975 2012-12-25 00:57:24.386340608   3483.807111     51      False   \n",
       " 976 2010-09-17 18:59:15.931293440           NaN     52      False   \n",
       " 977 2012-04-18 06:40:20.102041344   2869.173605     50      False   \n",
       " 978 2010-01-18 10:21:26.293353216           NaN     49      False   \n",
       " 979 2010-08-13 00:08:32.324416256           NaN     50      False   \n",
       " 980 2012-01-17 04:04:26.614297088           NaN     50      False   \n",
       " 981 2011-06-23 01:40:48.209999104           NaN     48      False   \n",
       " 982 2012-05-15 04:01:02.762140160   3935.159830     50      False   \n",
       " 983 2011-03-03 10:20:57.530126848   5704.369183     52      False   \n",
       " 984 2011-09-11 11:54:13.537061888  -3939.448245     49      False   \n",
       " 985 2012-07-01 08:38:12.122587648           NaN     49      False   \n",
       " 986 2013-01-15 14:24:51.253277952   7802.046675     52      False   \n",
       " 987 2011-03-16 12:56:22.305051648           NaN     49      False   \n",
       " 988 2012-02-09 21:21:51.383019776   3563.474259     50      False   \n",
       " 989 2011-04-28 07:35:57.312682752           NaN     49      False   \n",
       " 990 2012-07-06 11:32:42.706951424   4134.684319     48      False   \n",
       " 991 2012-09-10 11:27:22.375229184   2670.997722     48      False   \n",
       " 992 2010-04-19 00:59:34.282525696           NaN     51      False   \n",
       " 993 2012-05-21 02:19:56.773740288    725.161402     51      False   \n",
       " 994 2012-08-25 02:46:15.815232768   2736.817373     52      False   \n",
       " 995 2011-11-27 15:29:59.302161664           NaN     48      False   \n",
       " 996 2012-11-19 23:22:47.651802880           NaN     49      False   \n",
       " 997 2012-03-06 18:23:43.093342208           NaN     51       True   \n",
       " 998 2011-11-17 03:00:20.669487872           NaN     50      False   \n",
       " 999 2010-10-18 08:04:04.443984128           NaN     51      False   \n",
       " \n",
       "        MarkDown4     MarkDown3  Fuel_Price  Unemployment  Temperature  \\\n",
       " 0    2262.924323   4314.258484    2.944899     12.207513    44.866684   \n",
       " 1     648.327530           NaN    3.415876      8.296209    79.755000   \n",
       " 2    7464.648400   4818.694540    3.438865     10.375869    53.011465   \n",
       " 3    7722.936675           NaN    3.238451      8.340640    81.331769   \n",
       " 4     385.720439   2933.746873    3.352123      4.517977    33.216711   \n",
       " 5            NaN           NaN    2.595952      8.423675    58.153432   \n",
       " 6            NaN           NaN    3.337125      7.289977    68.198691   \n",
       " 7    1376.144152  -1375.405701    3.586827      4.433586    57.457667   \n",
       " 8            NaN    885.964999    3.132711      7.941049    82.624443   \n",
       " 9    4380.021000   4861.726545    4.617105      7.636990    64.616449   \n",
       " 10           NaN           NaN    3.490697      9.699187   113.890285   \n",
       " 11           NaN           NaN    3.337917     10.428851    76.354063   \n",
       " 12           NaN           NaN    3.016818     10.044523    52.925513   \n",
       " 13           NaN   1505.002284    3.244111      7.329469    34.127333   \n",
       " 14           NaN           NaN    2.497412     12.247448   100.350997   \n",
       " 15   7982.863954   7539.825400    3.909380      5.689230    65.945165   \n",
       " 16           NaN           NaN    2.895094      7.718521    54.750702   \n",
       " 17           NaN           NaN    3.722465      7.339952    56.152632   \n",
       " 18           NaN           NaN    2.665366      8.045471    78.257558   \n",
       " 19  -3310.004199   -808.378062    4.379650      5.320308    39.604265   \n",
       " 20           NaN   4604.622951    3.058964      8.584222    44.177016   \n",
       " 21   3790.217545   3053.642374    3.091990      5.069122    25.777591   \n",
       " 22           NaN           NaN    2.931042      9.062068    41.649615   \n",
       " 23           NaN           NaN    3.721348      6.586825    67.785117   \n",
       " 24   4610.034450   -617.120861    4.010528      8.686732    35.445785   \n",
       " 25           NaN           NaN    3.249523      8.450699    38.639637   \n",
       " 26   4005.965014    -28.792693    3.808513      9.188265    57.584018   \n",
       " 27   6433.867544  -3996.702966    2.976900      8.991618     6.179927   \n",
       " 28           NaN           NaN    3.208463     11.875517    50.400717   \n",
       " 29           NaN           NaN    3.455848      7.377382    56.480212   \n",
       " ..           ...           ...         ...           ...          ...   \n",
       " 970  7130.653517    613.434417    3.798558      8.849840    45.081481   \n",
       " 971  -950.449794   8369.741392    3.691277      8.687173    21.625873   \n",
       " 972  1423.082811   3915.095969    3.716980      7.812599    38.891102   \n",
       " 973          NaN           NaN    3.277952      7.881991    74.018427   \n",
       " 974          NaN           NaN    3.444190      4.147388    79.128181   \n",
       " 975  5645.978692   3893.099917    3.821702      8.410268    87.162204   \n",
       " 976          NaN           NaN    2.640021      7.458197    35.588448   \n",
       " 977 -2627.096894   -142.014936    3.320107      6.970687    49.700872   \n",
       " 978          NaN           NaN    2.710125      9.927722    83.348488   \n",
       " 979          NaN           NaN    3.139506      8.348364    46.708000   \n",
       " 980          NaN           NaN    3.578857      7.555184    25.595379   \n",
       " 981          NaN  -1147.726465    3.685507      9.407928    91.745352   \n",
       " 982   375.025287  11130.134824    3.467141      6.285321    38.179293   \n",
       " 983          NaN           NaN    2.675670     10.258619    50.599203   \n",
       " 984          NaN           NaN    3.375990      9.175979    44.036130   \n",
       " 985          NaN    649.171815    3.370836      6.948002    22.863602   \n",
       " 986  1944.149217    896.663662    3.971550      6.242637    97.107161   \n",
       " 987          NaN           NaN    3.524965      7.059279    65.469921   \n",
       " 988  2550.079436    121.672409    2.898533      5.929999    58.612442   \n",
       " 989          NaN           NaN    3.237647      6.992924    72.225708   \n",
       " 990          NaN           NaN    4.075160      8.392256    80.837964   \n",
       " 991 -1543.390402   5264.766267    3.157407      7.017727    81.515109   \n",
       " 992          NaN           NaN    3.293817      8.719239    65.735676   \n",
       " 993   932.568195   1845.259380    3.157982      7.494639    65.103553   \n",
       " 994 -2905.284812  -1268.636611    3.776062      6.736775    46.083801   \n",
       " 995          NaN           NaN    3.424730           NaN    79.231321   \n",
       " 996  9027.387381           NaN    3.960882      8.911136    26.948635   \n",
       " 997          NaN           NaN    3.764028      8.049413   111.723841   \n",
       " 998          NaN   6261.182193    3.609560      6.024725    38.411214   \n",
       " 999          NaN           NaN    3.051021      7.855145    75.446009   \n",
       " \n",
       "        MarkDown5    MarkDown2         CPI  \n",
       " 0    7218.910186          NaN  154.437715  \n",
       " 1    4928.572337  1860.474257  126.006100  \n",
       " 2    4381.712904  6491.080062  182.505905  \n",
       " 3            NaN  2075.661361  170.252793  \n",
       " 4   -1363.927516  6383.011111  181.850615  \n",
       " 5            NaN          NaN  250.558631  \n",
       " 6            NaN          NaN  213.846371  \n",
       " 7    1644.489130  4966.726612  189.105468  \n",
       " 8            NaN  4689.948004  152.931090  \n",
       " 9    3291.191563  2344.032770  152.780297  \n",
       " 10           NaN          NaN  195.602913  \n",
       " 11           NaN          NaN  176.381561  \n",
       " 12           NaN          NaN  147.881741  \n",
       " 13   1668.882903          NaN  155.004680  \n",
       " 14           NaN          NaN  193.442985  \n",
       " 15   1437.517079  4874.558939  152.281926  \n",
       " 16   8439.806431          NaN  130.530240  \n",
       " 17           NaN          NaN  201.486725  \n",
       " 18           NaN          NaN  188.760741  \n",
       " 19  -6907.068884  3246.451314  108.120768  \n",
       " 20           NaN          NaN  148.788886  \n",
       " 21   5724.976324  4496.854628  190.036218  \n",
       " 22           NaN          NaN  181.746008  \n",
       " 23           NaN          NaN  200.412670  \n",
       " 24   6637.078664 -1388.022496   87.164451  \n",
       " 25           NaN          NaN  195.622231  \n",
       " 26   2922.749710          NaN  224.233432  \n",
       " 27  -3042.801607          NaN  131.909287  \n",
       " 28   7063.102432          NaN  146.156666  \n",
       " 29           NaN          NaN  176.694595  \n",
       " ..           ...          ...         ...  \n",
       " 970  2882.447318          NaN  148.323409  \n",
       " 971  1918.923930          NaN  141.723698  \n",
       " 972   151.136535  1221.530133  155.532651  \n",
       " 973          NaN          NaN  213.405340  \n",
       " 974          NaN          NaN  186.636286  \n",
       " 975  2598.731935  -846.566855  190.957987  \n",
       " 976          NaN          NaN  153.917260  \n",
       " 977  8372.618269  1768.408869  249.068471  \n",
       " 978          NaN          NaN  177.318454  \n",
       " 979          NaN          NaN  208.719040  \n",
       " 980          NaN   754.021358  108.580497  \n",
       " 981          NaN          NaN  159.526588  \n",
       " 982  7349.003146  -732.495611  173.559001  \n",
       " 983          NaN          NaN  140.910196  \n",
       " 984   401.319810          NaN  175.340840  \n",
       " 985          NaN          NaN  171.683362  \n",
       " 986  -465.292159  -744.114065  177.553651  \n",
       " 987          NaN          NaN  144.344477  \n",
       " 988   567.400188          NaN  213.833680  \n",
       " 989          NaN          NaN  157.113353  \n",
       " 990          NaN  -232.801449  132.592027  \n",
       " 991   -72.622621          NaN  207.754643  \n",
       " 992          NaN          NaN  132.575018  \n",
       " 993  4955.778653  4683.646548  160.260401  \n",
       " 994  2898.089751          NaN  129.801694  \n",
       " 995          NaN          NaN         NaN  \n",
       " 996          NaN   608.026190  115.452177  \n",
       " 997          NaN          NaN  206.323679  \n",
       " 998          NaN  7020.489423  178.966240  \n",
       " 999          NaN          NaN  152.636567  \n",
       " \n",
       " [1000 rows x 12 columns]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdv.sample('features', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDV has tools to evaluate the synthetic data generated and compare them with the original data. To see more about the evaluation tools, [see the documentation](https://sdv-dev.github.io/SDV/api/sdv.evaluation.html#sdv.evaluation.evaluate)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
